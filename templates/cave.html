<div class="container">

  <h2 id="top">Completely Automated Alignment and Vowel Extraction</h2>

  <p class="lead">Our automated system takes uploaded audio files and returns ASR
    transcriptions, alignments, and vowel formant measurements.</p>

      <p> It is recommended that you look through the <a href="about">discussion</a> on the completely automated system's functionality and limitations before you begin. </p>

  <ul class="list-group">

<!--
    <li class="list-group-item"><h3>Audio with transcriptions provided by Google's speech recognition</h3>
    <p> <a class="btn btn-xs btn-success" href="googlespeech" role="button">Try it out</a></p>
-->

<li class="list-group-item"><h3>Audio with transcriptions provided by our in-house speech recognition</h3>
  <p>
    This system uses ASR built upon the CMU Sphinx framework to transcribe your data
    and then runs it through automated alignment and extraction using ProsodyLab Aligner and
    FAVE-Extract.

    It also provides the facility to edit the transcripts produced by the speech recognizer,
    and rerun the analysis.
  </p>
<p> <a class="btn btn-xs btn-success" href="uploadsound" role="button">Try it out</a></p>

    <li class="list-group-item">
<h3>ASR evaluation</h3>
    <p>   Automated data analysis requires a higher tolerance of potential noise in the alignment and formant extraction results. You can estimate this noise using our transcription evaluation tool, which takes a <strong> manual transcription</strong> of your recording along with the <strong>ASR transcription</strong> of the same, and uses weighted <a href="https://en.wikipedia.org/wiki/Levenshtein_distance">Levenshtein distance</a> to compute error rates for words, phonemes, and stressed vowels.</p>

    <p> <a class="btn btn-xs btn-success" href="uploadeval" role="button">Evaluate</a></p>

    </li>

  </ul>



</div> <!-- ends container -->
