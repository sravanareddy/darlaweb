<div class="container">

  <h2>FAQs</h2>


  <ol class="list-group">
    <li class="list-group-item">
    <a href="#" data-toggle="collapse" data-target="#whatbody"><h3
    id="what">
    What is DARLA?</h3></a>

    <div id="whatbody" class="collapse">
      <p>DARLA is a web application providing two main functionalities for vowel
    extraction from speech: completely
    automated and semi-automated.</p>

<p>The completely automated system transcribes the input
    speech data using automatic speech recognition (ASR), and then
    runs it through forced alignment and formant extraction. There is also a new option to use a system called Bed Word, which provides industry-quality transcriptions.</p>

    <p>The semi-automated system is a forced-alignment approach that
    aligns and extracts vowel formants from speech with manual
      transcriptions.</p></div>
      </li>

      <li class="list-group-item">

      <a href="#" data-toggle="collapse" data-target="#outputbody"><h3
      id="output">What output does the system return?</h3></a>

       <div id="outputbody" class="collapse">
<p>We e-mail a set of files to you: a vowel plot showing the mean of all vowels
  in your data (including both stressed and unstressed vowels)
and a spreadsheet with both unnormalized and Lobanov-normalized
formant measurements,
the same spreadsheet formatted for convenient uploading to <a
href="http://lingtools.uoregon.edu/norm/">NORM</a>, the
alignments, and the transcriptions.
You can select whether you want to filter out stop words
<a href="stopwords">(from this list)</a>
and high-bandwidth vowels.
</p>

<p>We recommend removing the unstressed vowels from your spreadsheet
  output before plotting it in NORM.
</p>

<p>
  We also recommend that you manually organize your DARLA
  output into word classes like LOT, THOUGHT, NORTH, FORCE, and so on
  (e.g. following
  <a href="http://www.phon.ucl.ac.uk/home/wells/stanlexsets.htm">Wells' 1982 lexical sets</a>
  and/or the vowel classes defined in ANAE word lists), rather than simply analyzing
  the data according to the vowel categories that come out of the CMU dictionary,
  which we use for alignment and extraction.
  The CMU dictionary (as used by both FAVE and DARLA)
  occasionally doesn't show the level of pronunciation detail
  needed for some subtle distinctions, mergers, etc., needed by sociolinguists.

</p>
       </div>

    </li>

    <li class="list-group-item">
    <a href="#" data-toggle="collapse" data-target="#asrbody">
    <h3 id="asr">What ASR is used for the completely automated feature?</h3></a>

     <div id="asrbody" class="collapse">
    <p>
      For Bed Word, we are using a third party company called Deepgram, which has its own state-of-the-art model. <br>
      We also have an older, in-house option, which is a model that is trained on over 400 hours of speech data with the CMU
      Sphinx toolkit.
     </div></li>

       <li class="list-group-item">
  <a href="#asr" data-toggle="collapse" data-target="#evalbody">
      <h3 id="eval">How can I evaluate the accuracy of the ASR transcriptions?</h3></a>

  <div id="evalbody" class="collapse">
    <p>
    <a href="asreval">Our online transcription evaluation tool</a>
    uses the weighted Levenshtein distance algorithm to compute
   transcription error rates for words, phonemes, and stressed vowels. Simply
    upload the ASR transcription and the manual transcription in
    plaintext format.</p>

</div></li>



  <li class="list-group-item">
  <a href="#eval" data-toggle="collapse" data-target="#techbody">
      <h3 id="tech">What do you use for alignment and extraction?</h3></a>

  <div id="techbody" class="collapse">
<p>We use the same methods as FAVE. Our forced alignment is done with the
  <a href="http://montreal-forced-aligner.readthedocs.io/">Montreal Forced Aligner</a>,
  and formant measurement with <a
  href="https://github.com/JoFrhwld/FAVE/tree/master/FAVE-extract">FAVE-extract</a>.
  We also use the <a href="http://cran.r-project.org/web/packages/vowels/index.html">R vowels package</a> for plotting.</p>
  <p>
    Here is a recent paper that tested DARLA's alignment system: MacKenzie, Laurel, and Danielle Turton (2020). Assessing the accuracy of existing forced alignment software on varieties of British English. Linguistics Vanguard.
    <a target="_blank" href="https://doi.org/10.1515/lingvan-2018-0061">https://doi.org/10.1515/lingvan-2018-0061 </a>


  </p>
</div></li>

<li class="list-group-item">
<a href="#tech" data-toggle="collapse" data-target="#dictbody">
    <h3 id="dict">Which pronunciation dictionary do you use?</h3></a>

<div id="dictbody" class="collapse">
<p>We use the CMU pronouncing dictionary,
  with some manual edits. You can check
  <a href="cmudict">the current version of the dictionary here</a>.
Note: We recommend
processing your data in terms of lexical sets like LOT, THOUGHT, NORTH,
FORCE, etc., rather than simply depending on the vowel sets as defined by the
CMU dictionary (like AA, AO, etc.). Like FAVE, DARLA depends on the CMU
dictionary to assign vowel symbols for each given word in your transcription, and
we occasionally find places in that dictionary where it doesnâ€™t have the level of
fine-grained pronunciation detail needed for various splits and mergers of interest
to sociolinguists.
</p>
</div></li>

    <li class="list-group-item">
    <a href="#dict" data-toggle="collapse" data-target="#whybody">
    <h3 id="why">Why completely automate vowel extraction?</h3>
    </a>

     <div class="collapse" id="whybody">
<p>In recent years, sociolinguists have begun using semi-automated speech processing methods such as Penn's <a href="http://fave.ling.upenn.edu/index.html">FAVE</a> program to extract vowel formants. These systems have accelerated the pace of linguistic research, but require significant human effort to manually create sentence-level transcriptions. </p>

<p>We believe that sociolinguistics is on the brink of an even more
  transformative technology: large-scale, completely automated vowel
  extraction without any need for human transcription. This technology
  would make it possible to quickly extract pronunciation features
  from hours of recordings, including YouTube and vast audio
    archives. DARLA takes a step in this direction. </p>
  </div>

      </li>

      <li class="list-group-item">
<a href="#why" data-toggle="collapse" data-target="#errorsbody">
      <h3 id="errors">How do we deal with ASR errors?</h3></a>

      <div class="collapse" id="errorsbody">
<p>While ASR is not perfect, we believe sociophoneticians do not need to wait for years to take advantage of speech recognition. Unlike applications like dictation software where accurate word recognition is the primary goal, sociophonetics typically focuses on a much narrower objective: extracting a representative vowel space for speakers, based on stressed vowel tokens.
For example, it would usually not be crucial to know that the stressed vowel in the word "turning" was extracted from "turn it" rather than "turning", or that "tack" was wrongly transcribed as "sack".  Such differences will have little effect on the speaker's vowel space for many sociophonetic questions. </p>

<p>It turns out that most ASR errors affect the identity of the <i>words</i> but not the identity of the <i>vowels</i> (especially stressed vowels), making it an ideal technology for automated vowel analysis.
Of course, there will be instances of vowel error, but the effect of these errors is reduced by the large amount of data with hundreds or thousands of vowel tokens.</p>

<p>Important contrasts like "cot" versus "caught" tend to be handled by ASR's modeling of grammatical plausibility (using a <a href="http://en.wikipedia.org/wiki/Language_model">language model</a>). The system would be unlikely to transcribe "I caught the ball" as "I cot the ball" since the latter would be improbable under an English language model.</p>

<p>Finally, since DARLA shows probabilities for the phonetic
	environment around each vowel (e.g., obstruent+vowel+nasal
	consonant), researchers can examine contrasts like pin/pen
	versus pit/pet.</p>
      </div>
      </li>

      <li class="list-group-item">

      <a href="#errors" data-toggle="collapse" data-target="#limitsbody">
      <h3 id="limits">Sounds great! What's the catch with the completely automated system?</h3></a>

       <div class="collapse" id="limitsbody">
<p> DARLA's completely automated system cannot provide perfect transcriptions. DARLA's completely automated approach to sociophonetics may help open the way
toward large-scale audio analysis, but there is a tradeoff. As with
many other sciences, automated processing necessitates error-reporting
in the measurements, not just in the statistical modeling. We find
that the system can be useful for extracting a representative vowel
	 space for sociophonetic purposes, as long as error levels are
	 considered and reported. In other words, fast large-scale
	 data analysis requires a higher tolerance of noise in the
	 data. If you need greater accuracy, please use our semi-automated system instead.</p>
       </div>

       </li>


       <li class="list-group-item">
        <a href="#privacy" data-toggle="collapse" data-target="#privacybody">
              <h3 id="errors">Does DARLA use my audio data for other services? How is it stored?</h3></a>
        
              <div class="collapse" id="privacybody">
        <p> When using any of DARLA's in-house services, your files are uploaded to the DARLA servers, where they are processed and then deleted later. We will not use your data or your email address 
          for any other purpose. <br>
        For Bed Word, since we use Deepgram as a third-party service, we upload your audio data to Deepgram's servers. We do not provide your email address to Deepgram. <a target="_blank" href="https://deepgram.com/privacy/">Per their privacy notice</a>,
        Deepgram maintains the right to hold records of uploaded audio data but will not use it for any purpose without permission from the audio owner. As with any academic research, it is important to consult with your university's 
      Institutional Review Board when using third-party data services.</p>
              </div>
              </li>

       <li class="list-group-item">
       <a href="#limits" data-toggle="collapse" data-target="#semibody">
       <h3 id="semi">What is the semi-automated functionality? How
       does it differ from FAVE and other such tools?</h3></a>

       <div class="collapse" id="semibody">
<p>This is designed for research that requires accurate human
transcription.
Our semi-automated system relies heavily on code from the Montreal Forced
	 Aligner and FAVE, but
	 wraps it in a different interface and provides more output features.</p>

<p>DARLA allows you to upload your transcriptions in various
formats: as a plaintext file, or as a TextGrid with a pair of
boundaries around each transcribed sentence (the "Boundaries" option).
You can also upload manually aligned/corrected TextGrids for formant
	 extraction only. Another option is to use the completely
	 automated system to generate ASR transcriptions, and then
	 correct them using our online tool.</p>

	 <p>Some steps that require manual intervention
	 in FAVE, like creating pronunciations of words that are not
	 in the dictionary, are automated.</p>

<p> For research requiring perfect transcriptions:
<ol>
<li>
Use the <a href="cave">completely automated ASR</a> option
as a first pass and then correct the transcriptions
online with our playback tool, OR

<li>If you can spend the time to produce manual transcriptions,
using the semi-automated <a href="uploadbound">Boundaries</a> option.
The semi-automated <a href="uploadtxt">plaintext</a>
method works just as well, but you will need to delete noises,
laughter, interviewer's voice, etc. With the Boundaries method, such
deletions aren't necessary since you are simply putting boundaries
around the parts of the recording that you want.</p>
</ol>
</p>
       </div>

            <li class="list-group-item">

      <a href="#semi" data-toggle="collapse" data-target="#noisebody">
      <h3 id="noise">What about noise or multiple voices in the recording?</h3></a>

       <div class="collapse" id="noisebody">

	 <p>The Alignment and Vowel Extraction system cannot currently handle transcriptions with
	 multiple speakers in an automated way. However, Bed Word can remove interviewer audio. </p>

	 	<p>When DARLA processes a recording with noise, laughter, loud breaths, background
	 voices, music, etc., the ASR transcriptions or
      alignments are likely to be incorrect.
	 If your recording would require a great deal of pre-cleaning,
      you might want to consider manually transcribing with the
      semi-automated method rather than the completely automated
	 one.</p>

	<p>However, it is easy to manually delete extraneous sounds and
	voices in Praat (select the noise and
	click Cmd+X or Ctrl+X). </p>

	<p> If your recording includes an interviewer who doesn't have
	 a microphone, this quiet background voice can cause confusion
	 for the ASR and aligner.
	 The best solution is to delete the interviewer voice (see
	 above), but here are some other options:</p>

	 <ol>
	   <li> Try "smoothing out" the amplitude of all voices on the
	 recording: Load your file in Audacity, then click Effects >
	   Compressor.
	   That feature is a dynamic range adjuster which tries to
	   make all voices approximately the same
	   (pull the slider all the way to the left for the strongest effect). </li>
<li> Try reducing the amplitude of the whole recording (in Audacity,
	 click Effects > Amplify) so that the quieter voice is
	   non-existent.</li>
	   This may help remove quiet background voices that would be a problem for the aligner.
<li> You can also try increasing the amplitude of all voices so that
	 the ASR transcription can "hear" all of them clearly: In
	   Audacity, click Effects > Amplify.</li>
	  </ol>
	</div>
	</li>

	  <li class="list-group-item">
    <a href="#noise" data-toggle="collapse" data-target="#codebody"><h3
    id="code">
    Is the code for DARLA public? Can I contribute?</h3></a>

    <div id="codebody" class="collapse">
      <p><a href="#eval" data-toggle="collapse"
      data-target="#techbody">See this question</a> for links to the alignment,
      extraction, and plotting code written by other researchers that we are
      building upon.

<p>Our code for the rest of the system -- the web interface, the ASR,
     online correction and evaluation of transcripts,
      handling different file formats,
      etc. -- is currently not public because
      it is under active development. We also think that most users
      prefer the convenience of the web interface rather than
      installing and wrangling with several programs on their computers.</p>

      <p>If you are interested in contributing a new feature or
      modifying an existing functionality, please e-mail us! We are
      excited to collaborate on related linguistics and computer science
      research, as well as the software
      development front.
    </p>
    </div>
      </li>


    </ul>   <!-- ends list-group ul -->



</div>   <!-- ends container -->
